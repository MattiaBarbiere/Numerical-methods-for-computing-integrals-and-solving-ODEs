\documentclass[a4paper,12pt, total={21cm, 29cm}]{article}
% Required for inserting Images
\usepackage{graphicx}
\usepackage{subcaption}
%For adding clicable references
\usepackage[hidelinks]{hyperref}
%\usepackage{theoremref} I didn't use this as it messes up the font

%For tables
\usepackage{booktabs}
%Math
\usepackage[thinc]{esdiff}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
%For colours
\usepackage{xcolor}

\usepackage{geometry}
\geometry{left=2.5cm, right=2.5cm}



% %---------
\usepackage[pagewise]{lineno} % For numbering the lines pagewise
%\linenumbers
\usepackage{setspace} % To change the line spacing


%Setting 30 lines per page
\newlength{\linelength}
\setlength{\linelength}{\dimexpr(\textheight-2\baselineskip)/30\relax}
\setlength{\parindent}{0pt} % Remove the paragraph indentation

% Setting the line spacing
\linespread{\linelength\baselineskip}

%Reducing the space before and after equations
\setdisplayskipstretch{1}

%------------

\usepackage[T1]{fontenc}
\usepackage[scaled]{helvet}
\renewcommand*{\familydefault}{\sfdefault}

%For bibliography
\usepackage[backend=biber]{biblatex}
\addbibresource{refs.bib}


\begin{document}


%Commands
\renewcommand{\qed}{\hfill$\blacksquare$}
\newcommand{\R}{\mathbb{R}}
\newcommand{\tx}[1]{\quad \text{#1} \quad}
%\newcommand{\lb}[1]{\if\relax\detokenize{#1}\relax{\nonumber}\else{\label{#1}}\fi}

%Equation number depends on secton
\numberwithin{equation}{section}


%Definitions
%\theoremstyle{definition}
\newtheorem{df}{Definition}[section]
\newtheorem{ex}{Example}[section]
%Theorems and Lemmas
\newtheorem{thm}{Theorem}[section]
\newtheorem{corollary}{Corollary}[thm]
\newtheorem{lemma}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}

\null\thispagestyle{empty}\newpage
\null\thispagestyle{empty}\newpage
\textbf{Dedication or acknowledgements (if not included, a blank page)}\thispagestyle{empty}\newpage
\null\thispagestyle{empty}\newpage

%Resetting the page numbering
\clearpage
\pagenumbering{arabic}

\tableofcontents

\newpage

%---------------------------Introduction----------------------------------

\section{Introduction}
Integrals and differential equations are a vital tool used throughout mathematics. In particular, they are essential in many modelling real world problems throughout scientific disciplines. When we try to apply these tools in practice, however we encounter some difficulties, as it is often the case that no analytical solutions can be computed. This problem gave rise to \textit{numerical analysis} which tries to approximate the correct value without needing an explicit solution to the problem. After having developed all the theoretical concepts, we can easily translate this into computer code. For this reason, this paper goes hand in hand with a Jupyter Notebook available at \cite{Barbiere_Numerical_Method_for}. This notebook contains the implementations of all the numerical methods I cover, together with graphical illustrations, some of which are already included in this paper.

With this motivation in mind, I will now present an introductory dive into some important aspect of numerical analysis, with a particular emphasis on analysing methods to solve integrals and differential equations. In Section \ref{section_integrals} we will see that these two concepts often go hand in hand, which leads to many similarities between numerical methods. Before starting with the methods I will devote some time to polynomial interpolation which is at the heart of many derivations in numerical analysis.

%---------------------------Polynomial Interpolation------------------------------

\section{Polynomial Interpolation}
%https://services.math.duke.edu/~jtwong/math563-2020/lectures/Lec1-polyinterp.pdf
%For proof of lagrange theorem:
%https://math.okstate.edu/people/binegar/4513-F98/4513-l16.pdf
Throughout numerical analysis we encounter problems that have to deal with very intricate and complicated functions which often cause trouble when we try applying our mathematical tools on them. To try and overcome these issues, we must find clever ways to approximate the complicated functions with simpler and more mathematically tractable ones. Polynomials seems to check all the boxes in this case. They are very easy to manipulate and to perform operations on. Furthermore, they are extremely versatile as you can increase their degree and play around with their coefficients to approximate essentially any function. Actually, the Weierstrass Approximation Theorem \ref{W_approx_thm} states that any continuous function on a closed interval $[a,b]$ can be approximated to an arbitrary level of precision by a polynomial.
This theorem, however, does not tell us how to find such a polynomial. A classic why of finding a possible polynomial is using a Taylor expansion. While this is very powerful in itself, in this chapter we will explore another why of finding a polynomial approximation of a function: \textit{Lagrange polynomial interpolation}.\\
{\color{white}-}\\
Given a function $f$ and $n+1$ points $\{x_0, \dots , x_n\}$ (data points for example) define
\begin{equation}\nonumber
    y_i := f(x_i) \tx{for} i \in \{0,\dots,n\}
\end{equation}
We say a function $p(x)$ is an \textit{interpolant} for $f(x)$ if $p(x)$ matches $f(x)$ at the $n+1$ points,
\begin{equation}\label{poly_interpolation_conditions}
    p(x_i) = y_i \tx{for} i \in \{0,\dots,n\}
\end{equation}
We will focus on interpolations with polynomials throughout this paper, but this idea can be generalized to other classes of functions. On a side note, I often use interpolation and approximation interchangeably, however they are not the same thing. Interpolation is a method that may or may not be a useful approximation. All we say is that it must match the function at a finite amount of points. A priori, there is no reason to believe that this may work as a good approximation. Luckily, in numerical analysis interpolation works very well! Its main usefulness is when we have a finite number of data points and finite values of a function. In this case, methods like Taylor series will fail as we have no real knowledge about derivatives. When we have complete knowledge about the function it may be a lot better to use a Taylor's approximation compared to a polynomial interpolation.\\
{\color{white}-}\\
Our objective is to construct a polynomial that satisfies \eqref{poly_interpolation_conditions}. The construction of $p(x)$ with the Lagrange method comes down to understanding the Lagrange basis.
\begin{equation}\nonumber
    l_i(x)=\prod_{j: j \neq i} \frac{x-x_j}{x_i-x_j}
\end{equation}
By simple inspection, we notice that for all $k \neq i$,
\begin{equation}\nonumber
     l_i(x_k) = \prod_{j: j \neq i} \frac{x_k-x_j}{x_i-x_j} = 0 \tx{and}  l_i(x_i) = \prod_{j: j \neq i} \frac{x_i-x_j}{x_i-x_j} = \prod_{j: j \neq i} 1 = 1
\end{equation}
This is basically the Kronecker delta constructed with polynomials. Using these n-th degree polynomials we can easily construct our interpolant polynomial as
\begin{equation}\label{poly_interpolation}
    p(x) = \sum_{i=0}^{n}y_i \, l_i(x)
\end{equation}
This polynomial turns out to be unique among all the polynomials of degree $n$.
\begin{prop}[Uniqueness of degree at most n]\label{uniqueness_of_interp}
    Given a function $f:\R \longrightarrow \R$ and $n+1$ points,
    \begin{equation}
        x_0<x_1<x_2<\dots<x_{n-1}<x_n \quad \text{with} \quad x_i \in [a,b]\quad \forall i \in \{0,\dots,n\} \nonumber
    \end{equation}
    Let $p_n(x)$ be the interpolating polynomial such that $deg(p_n) \leq n$. Then $p_n(x)$ is the unique polynomial of degree at most n that satisfies \eqref{poly_interpolation_conditions} with respect to $f$.
\end{prop}
\begin{proof}
    Assume, by contradiction, that there exist two polynomials $p_n$ and $q_n$ such that
    \begin{equation}
        deg(p_n),deg(q_n) \leq n \quad \text{and} \quad \exists x \in [a,b]: p_n(x) \neq q_n(x) \nonumber
    \end{equation}
    Define $r(x) = p_n(x) - q_n(x)$ which implies that $deg(R) \leq n$. Moreover, notice that
    \begin{equation}
        r(x_i) = p_n(x_i) - q_n(x_i) = 0 \quad \forall i \in \{0,\dots,n\} \nonumber
    \end{equation}
    By the Fundamental Theorem of Algebra a polynomial of degree at most $n$, must have at most $n$ roots, however $r(x)$ has $n+1$ roots and $deg(r) \leq n$ which implies that $r(x) = 0 \quad \forall x \in [a,b]$. This mean that $p_n(x) = q_n(x)\quad \forall x \in [a,b]$ which gives a contradiction.
\end{proof}

%---------------------------Error analysis of interpolation---------------------

\subsection{Error analysis of Lagrange polynomial interpolation}
Many of the numerical method I will cover start from a polynomial interpolation of the function in question. To provide a detailed error analysis of the methods to come, we must first understand the error that comes from polynomial interpolation. To this end we have the following theorem.
\begin{thm}[Lagrange error formula]\label{Err_interpolation_thm}
    Assume $f \in C^{\,n+1}([a,b])$ with $n+1$ points
    \begin{equation}\nonumber
        x_0<x_1<x_2<\dots<x_{n-1}<x_n \quad \text{with} \quad x_i \in [a,b]\quad \forall i \in \{0,\dots,n\} \nonumber
    \end{equation}
    Let $p_n(x)$ be the interpolating polynomial of degree n. Then for all $x \in [a,b]$
    \begin{equation}\nonumber
        f(x) = p_n(x) + E_n(x)\nonumber
    \end{equation}
    with $E_n(x)$ the interpolation error which takes value
    \begin{equation}\label{Err_interpolation}
        E_n(x) = \frac{f^{(n+1)}(\eta_x)}{(n+1)!}\prod_{j=0}^{n}(x-x_j)
    \end{equation}
    for some $\eta_x \in [a,b].$
\end{thm}
\begin{proof}
    A proof of this theorem can be found in \cite{gautschi2011numerical}
\end{proof}

Let's take a better look at \eqref{Err_interpolation}. The first term we see is the (n+1)-th derivative. As we are working with a compact interval, we can easily bound this by taking the $\max_{x \in [a,b]} |f^{(n+1)}(x)|$. As we decrease the interval size, this value may decrease or stay the same depending on the function.\\
The second term is $\frac{1}{(n+1)!}$ which, lucky for us, goes to 0 very quickly as $n \to +\infty$.\\
The last term is what we call $\omega(x)$:
\begin{equation}\nonumber
    \omega(x) := \prod_{j=0}^{n}(x-x_j)
\end{equation}
We can see that $\omega(x)$ will be small if $x$ is close to one of the points and will be large otherwise.\\
The error analysis essentially boils down to which factor will have a bigger effect on the upper bound as we increase the number of points at our disposal. The upper bound on an interval $I$ is of the form
\begin{equation}\nonumber
    |E_n(x)| \leq \frac{\max_{x \in I} |f^{(n+1)}(x)|}{(n+1)!}\max_{x \in I} |\omega(x)|
\end{equation}

%---------------------------Runge phenomenon----------------------------------

\subsection{Convergence of Lagrangian interpolation}
The next question that comes to mind is whether the interpolation error goes to 0 as we increase the degree of the polynomial. The answer to this depends on our choice of the interpolation points. All the methods I will present will assume that the data points are evenly spaced with size $h$. In doing so, however, we risk running into a problem of the interpolation polynomial diverging from the function. The next example illustrates an instance in which this happens.

\subsubsection{Runge's phenomenon}
Consider the interval $[-5,5]$ and the following $C^{\infty}([-5,5])$ function over that interval,
\begin{equation}\label{Runge_function}
    G(x) := \frac{1}{1 + x^2}
\end{equation}
If we try and interpolate this function using a uniform grid we see that towards the edges the polynomial starts to rapidly oscillate.

\begin{center}
    \includegraphics[width=0.75\textwidth]{Images/runge phenomenon.png}
\end{center}

For larger values of n this behaviour only gets worse. The problem of this function is that the n-th derivatives blow up in the interval $[-5,5]$. Some empirical evidence of this is available in the Jupyter Notebook \cite{Barbiere_Numerical_Method_for}.
% \begin{center}
%     \begin{tabular}{c c c}
%     \toprule
%     n & $\max f^{(n)}(x)$ & $\min |f^{(n)}(x)|$\\
%     \midrule
%     0 & 9.999937e-01 & 3.846154e-02\\
%     5 & 1.004582e+02 & 1.004582e+02\\
%     10 & 2.393788e+06 & 3.627302e+06\\
%     15 & 1.216009e+12 & 1.216009e+12\\
%     20 & 2.429387e+18 & 1.941923e+18\\
%     \bottomrule
%     \end{tabular}
% \end{center}


% More precisely if we were to plot $\max_{x \in [-5,5]} |G^{(n)}(x)|$ and $\min_{x \in [-5,5]} |G^{(n)}(x)|$ as a function of $n$ on a logarithmic scale we can see that this blow up actually grows exponentially in $n$.\\
% {\color{white}-}\\
% \begin{minipage}[b]{0.5\textwidth}
%     \includegraphics[width=\textwidth]{Images/max over log scale.png}
% \end{minipage}%
% \begin{minipage}[b]{0.5\textwidth}
%     \includegraphics[width=\textwidth]{Images/min over log scale.png}
% \end{minipage}%

It might seem that we have little hope of working with the polynomial interpolation with evenly spaced points, luckily for us there are a few workarounds that we can exploit. The main solution that most derivations will use is \textit{spline interpolation}. Essentially, what this does is to break up the interval into many subintervals. This actually has a few advantages. The first and foremost is that we avoid the bad behaviour seen above. Secondly, it allows us to work with lower degree polynomials, which reduces complexity. Lastly, by reducing the size of the subintervals, if our function is smooth enough, we can approximate very well the function with our low degree interpolating polynomial. Below we can see that spline interpolation works very well even with the problematic Runge function $G(x)$.

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{Images/Spline interpolation.png}
    \caption{Caption}
    \label{fig:enter-label}
\end{figure}

With this solution in mind, numerical methods boil down to working over each subinterval individually and then combining all the answers.

%---------------------------Integrals----------------------------------

\section{Numerical Methods for Solving Integrals}\label{section_integrals}
Before directly analysing methods for solving differential equations, we first explore some methods for numerically solving integrals. This is motivated by the fact that often differential equations and integrals are essentially the same thing.
Take a differential equation as defined in \eqref{IVP}. The assumptions in the Picard–Lindel\"{o}f Theorem \ref{picard_thm} needed to guarantee the existence and uniqueness of a solution are also enough for us to conclude that the function $f$ is Riemann integrable over the first variable. Taking the integral of the ODE.
\begin{equation} \nonumber
    \int_{t_{0}}^{t}f(s,y(s))ds = \int_{t_{0}}^{t}y'(s) ds = y(t) - y(t_{0}) = y(t) - y_{0}
\end{equation}
Giving us the equation
\begin{equation}\label{Integral_ODE}
    y(t) = y_{0} + \int_{t_{0}}^{t}f(s,y(s))ds
\end{equation}
By building methods to solve integrals, we are often able to make good progress in numerically solving differential equations. I will discuss the Trapezoidal Rule and Simpson's rule for integration, and in later sections we will see how these can be transformed into methods for solving ODEs.

%---------------------------Trap Rule----------------------------------

\subsection{Trapezoidal Rule for Integration}\label{trap_method}
Given any function $f: \R \longrightarrow \R$ our objective is to compute 
\begin{equation}\label{integral}
    I(f) = \int_{a}^{b}f(x)\,dx
\end{equation}
In light of what we know of polynomial interpolation, a first step would be to use the interpolation of $f$ of degree 1. From \eqref{poly_interpolation} we have
\begin{equation}\nonumber
    p(x) = \frac{x-a}{b-a} f(b) + \frac{b-x}{b-a} f(a)
\end{equation}
This polynomial provides a linear approximation of the function $f$ in the interval $[a,b]$. By integrating the polynomial, we could approximate the integral we are after. Geometrically, by integrating $p(x)$ we are calculating the area of a trapezoid with vertices $(a,0),$ $ (a,f(a)), (b, f(b))$ and $(b,0)$. Using the formula for the area of a trapezoid with height equal to $(b-a)$ we get
\begin{equation}\label{def_trap_single_interval}
    T_{1}(f) := \int_{a}^{b}p(x)\,dx = \frac{1}{2}(b-a)  (f(a) + f(b))
\end{equation}
If is very evident that if $b-a$ is very large, this could turn out to be a very crude approximation. The error denoted as $E_T(f)$ in fact is given by the following theorem.
\begin{thm}[Trapezoid method error with a single interval]\label{thm_trap_error_1_interval}
    Let $f \in C^2([a,b])$ and let $T_1(f)$ be the trapezoid approximation to $I(f)$ as defined in \eqref{def_trap_single_interval}. Then there exists $\xi \in [a,b]$ such that
    \begin{equation}\nonumber
        E_T(f) := I(f) - T_1(f) = -\frac{1}{12}f''(\xi)(b-a)^3
    \end{equation}
\end{thm}

\begin{proof}
    \begin{equation}\nonumber
        \begin{split}
            E_T(f) & =  I(f) - T_{1}(f)  = 
        \int_{a}^{b}f(x)\,dx - \int_{a}^{b}p(x)\,dx = \\
        & =\int_{a}^{b}(f(x) - p(x))\,dx = \frac{1}{2} \int_{a}^{b}((x-a)(x-b)f''(\eta_{x}))\,dx
        \end{split}    
    \end{equation}
    Where the last step comes from Theorem \ref{Err_interpolation_thm}.

    As $(x-a)(x-b) \leq 0$ on $[a,b]$ we use Theorem \ref{Gen_IMVT} we get that, for some $\xi \in [a,b]$:
    
    \begin{equation}\nonumber
    \begin{split}
        E_T(f) &= \frac{1}{2} \int_{a}^{b}(x-a)(x-b)f''(\eta_{x})\,dx=\\ 
        &= \frac{1}{2} f''(\xi) \int_{a}^{b}(x-a)(x-b)\,dx= \\ 
        &= \frac{-1}{12} f''(\xi) (b-a)^3
    \end{split} 
    \end{equation}
    As requested.
\end{proof}
As we expected, the error depends $b - a$. This means that if we have a large interval we may be very far away from the true value of the integral. Taking inspiration from spline interpolation, the trick is to divide the interval into many smaller intervals and then summing up the area of all the smaller trapezoids.\\
Take $n$ subintervals $[x_{i-1}, x_{i}]$ for $ i \in \{1,\dots,n\}$ with $x_0 = a$ and $x_n = b$. Our integral then becomes,
\begin{equation}\nonumber
    I(f) = \sum_{i=1}^{n} \int_{x_{i-1}}^{x_{i}} f(x)\,dx
\end{equation}
For each subinterval we follow the approximation of the previous part and we get
\begin{equation}\label{def_T_n}
    \sum_{i=1}^{n} \int_{x_{i-1}}^{x_{i}} f(x)\,dx \approx 
    \sum_{i=1}^{n} \frac{1}{2}(x_{i} - x_{i-1})  (f(x_{i}) + f(x_{i-1})) =: T_n(f)
\end{equation}


How we divide the interval $[a,b]$ will have an effect on the overall error of the approximation.

%---------------------------Trap uniform----------------------------------

\subsubsection{Trapezoid Method with uniform grid}
Under the assumption that the grid is uniform we can find an exact value of the error directly from the calculation of $E_T(f)$ in the previous section. This leads us to the following theorem.

\begin{thm}[Trapezoid method error with a uniform grid] \label{Err_uni}
    Let $f \in C^2([a,b])$ and let $T_n(f)$ be the n-subinterval trapezoid approximation to $I(f)$, using a uniform grid with subinterval size $h = \frac{b-a}{n}$. Then there exists $\xi \in [a,b]$ such that
    \begin{equation}\nonumber
        E_T(f) := I(f) - T_n(f) = -\frac{b-a}{12}h^2f''(\xi)
    \end{equation}
\end{thm}
\begin{proof}
    The proof consists of summing the result from Theorem \ref{thm_trap_error_1_interval} over all the subintervals. More details can be found in \cite{JE_Book}.
\end{proof}
From this theorem we can clearly see that the trapezoidal rule with uniform grid has an error of second order $O(h^2)$.

This gives us to the following important corollary.
\begin{corollary}\label{cor_err_uni}
    Let $f \in C^2([a,b])$ and let $T_n(f)$ be the n-subinterval trapezoid approximation to $I(f)$, using a uniform grid with subinterval size $h = \frac{b-a}{n}$. By letting the number of subintervals go to infinity or equivalently sending the size $h$ of the uniform grid to zero, we get that
    \begin{equation}\nonumber
        \lim_{n\to\infty} T_n(f) = I(f)
    \end{equation}
    
    \begin{proof}
    We clearly have that $\max_{x \in [a,b]}|f''(x)|$ is finite by the continuity of $f''$ over $[a,b]$. Taking the absolute value of Theorem \ref{Err_uni} and taking the limit gives the desired result.
       \begin{equation}
            \lim_{n\to\infty} |E_T(f)| = 
            \lim_{h\to0} \frac{b-a}{12}h^2|f''(\xi)|
            \leq \left(\lim_{h\to 0} \frac{b-a}{12}h^2\right)\max_{x \in [a,b]}|f''(x)| = 0\nonumber
        \end{equation}
    
    \end{proof}
\end{corollary}
So we are able to get the error sufficiently small by choosing $h$ small enough. In other words, to lower the error, all we have to do is increase the number of subintervals.

%---------------------------Trap non-uni----------------------------------

\subsubsection{Trapezoid Method with non-uniform grid}
If we have an arbitrary grid we are able to find an upper bound for the error depending on the size of the largest subinterval we have.

\begin{thm}[Trapezoid method error with a non-uniform grid] \label{Err_non_uni}
    Let $f \in C^2([a,b])$ and let $T_n(f)$ be the n-subinterval trapezoid approximation to $I(f)$, using a non-uniform grid defined by
    \begin{equation}\nonumber
        a=x_0<x_1<x_2<\dots<x_{n-1}<x_n = b
    \end{equation}
    
    with $h_i = x_{i+1} - x_i$ and $h = \max_{i} h_i$. Then 
    \begin{equation}\nonumber
        |E_n(f)| := |I(f) - T_n(f)| \leq \frac{b-a}{12}h^2\max_{x \in [a,b]}|f''(x)|
    \end{equation}
\end{thm}
\begin{proof}
    Similar to before but working with the new definition of h. 
\end{proof}
We can construct a corollary similar to Corollary \ref{cor_err_uni} however in this case increasing the number of subintervals will not guarantee that the error converges to 0. To see why, take a subinterval $\left[a,\frac{a+b}{2}\right]$. Now we can divide $\left[\frac{a+b}{2}, b\right]$ infinitely many times, however this will not lower the upper bound of our error, as the upper bound depends on $h = \max_{i} h_i$. So to make sure that our error goes to 0 we must make sure that all grid sizes go to 0 which is equivalent to imposing that the maximum grid size goes to 0. Similarly to the uniform case we also see that in this case the error has second order $O(h^2)$ paying careful attention to the definition of $h$ in this context.

%---------------------------Stability of trap----------------------------------

\subsubsection{Stability of the trapezoid rule}\label{sec_stab_trap_integration}
Other than the convergence to the correct value, another important aspect of approximations is stability. That is, if we slightly perturb the input function how does the value of our integral approximation change? We would like for the approximation to change very little and moreover, if we send the size of the perturbation to zero, the approximation should converge to the original value. This gives us a sense of \textit{stability} for integration methods. Often these methods are stable, however we will see that when we do a similar analysis for numerical ODEs this is not always the case.\\
Define $g(x) := f(x) + \epsilon(x)$ with $\epsilon(x)$ the slight perturbation of $f(x)$. What can we say about $|T_n(f) - T_n(g)|$ given that $|f(x) - g(x)| = |\epsilon(x)|$? Recall from equation \eqref{def_T_n} that
\begin{equation}\nonumber
    \begin{split}
        &T_n(f) = \sum_{i=1}^{n} \frac{1}{2}(x_{i} - x_{i-1})  (f(x_{i}) + f(x_{i-1})) \\
        &T_n(g) = \sum_{i=1}^{n} \frac{1}{2}(x_{i} - x_{i-1})  (g(x_{i})      + g(x_{i-1}))
    \end{split}
\end{equation}
Taking the difference gives
\begin{equation}\nonumber
    \begin{split}
        T_n(f) - T_n(g) & = \sum_{i=1}^{n} \frac{1}{2}(x_{i} - x_{i-1})  (f(x_{i}) + f(x_{i-1}) - g(x_{i}) - g(x_{i-1}))\\ 
        & = \sum_{i=1}^{n} \frac{1}{2}(x_{i} - x_{i-1})  (\epsilon(x_{i}) + \epsilon(x_{i-1}))
    \end{split}
\end{equation}
Taking the absolute value and bounding it from above gives,
\begin{equation}\nonumber
    |T_n(f) - T_n(g)| \leq 2\max_{x \in [a,b]}|\epsilon(x)|\sum_{i=1}^{n} \frac{1}{2}(x_{i} - x_{i-1}) = (b-a)\max_{x \in [a,b]}|\epsilon(x)|
\end{equation}
Where the last step comes from the fact that we have a telescoping sum and that $x_0 = a$ and $x_n = b$.\\
This tells us that if the maximum perturbation is sufficiently small also $|T_n(f) - T_n(g)|$ will be small. Actually if we let $\max_{x \in [a,b]}|\epsilon(x)| \to 0$ we get that $|T_n(f) - T_n(g)| \to 0$ which means $T_n(f) \to T_n(g)$ proving that the trapezoid method is numerically stable.

%--------------Diff vs non diff example for trap-------
\subsubsection{Trapezoid integration of Differentiable vs Non-differentiable functions}
I will now present a comparison of the trapezoid method applied to two similar function one of which will be differentiable everywhere and the other not. By plotting the error, we can compare the convergence of the trapezoid method applied to these two functions. When I say convergence. here I mean that the error between the approximated value and the correct value goes to 0.
\begin{ex}\label{diff_vs_non_diff}
    Consider the following two functions
    \begin{equation}\nonumber
        f(x) = \arccos\left(\cos\left(e^{x}\right)\right) \tx{and} g(x) = \frac{\pi}{2}\cos\left(e^{x}+\pi\right)+\frac{\pi}{2}
        \tx{for} x \in [ln(2\pi), ln(20\pi)]
    \end{equation}
\end{ex}

By plotting them over the interval we see that they are very similar. The main difference is that $f$ is not differentiable everywhere.

\begin{center}
    \includegraphics[width=\textwidth]{Images/diff vs non-diff.png}
\end{center}

By applying the trapezoid method to both functions and plotting the error as a function of n, we get the following graph.

\begin{center}
    \includegraphics[width=\textwidth]{Images/Error of trapezoid integration diff vs non diff.png}
\end{center}

We notice that the trapezoid method struggles with both functions at the beginning. This is due to the oscillatory nature of the functions which means the approximation cannot follow the functions well enough for small values of $n$. Once we get to $n \approx 25$ we see that for the differentiable function the error dramatically goes to 0, while for the non-differentiable function the method takes longer to reduce the error. Eventually, the error does decrease even for the non-differentiable function, but even at high values of $n$ we see some fluctuations.

This example illustrates the fact that numerical integration methods have an easier time approximating differentiable functions compared to non-differentiable. This is why many theorems that talk about approximation error assume some differentiability of the function.


%---------------------------intro Simpson's rule----------------------------------

\subsection{Simpson's Rule for Integration}\label{Simp_section}
%https://www.uio.no/studier/emner/matnat/math/MAT-INF1100/h11/kompendiet/chap12.pdf
In wake of the derivation of the trapezoid method, we can take the polynomial interpolation one step further. That is, for each (sub)interval $[a,b]$ we interpolate the function $f$ at $a, b, \frac{a+b}{2}$ with a second order polynomial. Recall that in the trapezoid method we only interpolate the end points of the intervals with a first degree polynomial. By increasing the degree of the polynomial we get Simpson's rule for integration.\\
Definite $m:=\frac{a+b}{2}$, our polynomial interpolation of $f$ at $a,b,$ and $m$ is
\begin{equation}\label{second_deg_interpolation}
    q_{a,b}(x) = f(a)\frac{(x-m)(x-b)}{(a-m)(a-b)} + f(m)\frac{(x-a)(x-b)}{(m-a)(m-b)} + 
    f(b)\frac{(x-a)(x-m)}{(b-a)(b-m)}
\end{equation}
To derive Simpson's method we could follow the steps as we did with the trapezoid method, however there is a more elegant derivation.

%---------------------------Simp on [-1.1]----------------------------------

\subsubsection{Specific case of Simpson's method}

Our aim is interpolating a function $f$ with a second degree polynomial in order to approximate the integral of $f$. Let's solve for the case when $a = -1, m=0$ and $b=1$:
\begin{equation}
    q_{-1,1}(x) = f(-1)\frac{x(x-1)}{2} - f(0)(x+1)(x-1) + 
    f(1)\frac{x(x+1)}{2}\nonumber
\end{equation}
As we did with the trapezoid method. The idea is that the integral of $q_{-1,1}(x)$ over $[-1,1]$ should approximate the integral of $f$ over the same interval.
\begin{equation}
    \int_{-1}^{1}q_{-1,1}(x)\,dx  \approx \int_{-1}^{1}f(x)\,dx  \nonumber
\end{equation}
Integrating $q_{-1,1}(x)$ on $[-1,1]$ gives
\begin{equation}
    \int_{-1}^{1}q_{-1,1}(x)\,dx = f(-1)\int_{-1}^{1}\frac{x(x-1)}{2}\,dx - f(0)\int_{-1}^{1}(x^2-1)\,dx + 
    f(1)\int_{-1}^{1}\frac{x(x+1)}{2}\,dx =\nonumber
\end{equation}

\begin{equation}\label{Simp_-1_1}
    = \frac{1}{3}(f(-1) + 4f(0) + f(1)) \approx \int_{-1}^{1}f(x)\,dx
\end{equation}

%---------------------------Simpson's rule----------------------------------

\subsubsection{Simpson's rule}\label{Simp_single_interval}

Now notice the following function
\begin{equation}\label{map_a_b}
    y(x)=\frac{2(x-a)}{b-a}-1 
\end{equation}
This function linearly maps $x \in [a,b]$ into $y(x) \in [-1,1]$.\\
We can now move to the general case. Using the inverse of \eqref{map_a_b} we can perform a substitution and we get
\begin{equation}
    x=\frac{b-a}{2}(y+1)+a \implies \,dx = \frac{b-a}{2}\,\,dy \nonumber
\end{equation}
\begin{equation}\nonumber
    I(f) = \int_{a}^{b}f(x)\,\,dx = \frac{b-a}{2}\int_{-1}^{1}f(\frac{b-a}{2}(y+1)+a)\,dy
\end{equation}
For clarity let's define $F(y):=f(\frac{b-a}{2}(y+1)+a)$, and using \eqref{Simp_-1_1} with $F(y)$ we get
\begin{equation}\nonumber
    \frac{b-a}{2}\int_{-1}^{1}F(y)\,dy \approx \frac{b-a}{2}\int_{-1}^{1}q_{-1,1}(x)\,dx = \frac{b-a}{6}(F(-1) + 4F(0) + F(1))
\end{equation}
Recalling that $F(-1) = f(a), F(0) = f(m), F(1) = f(b)$ and letting $h=\frac{b-a}{2}$ we have the Simpson's method for integration defined as
\begin{equation}\label{simp_approx}
    S_2(f) := \frac{h}{3}(f(a) + 4f(m) + f(b)) \approx I(f)
\end{equation}

%---------------------------Composite simp rule----------------------------------

\subsubsection{Composite Simpson's rule}
Recalling the motivation behind spline interpolation, we divide the interval $[a,b]$ in many subintervals and perform what we did in Section \ref{Simp_single_interval} on each subinterval. Since we need a middle point to perform our interpolation, each subinterval must contain three of our data points.\\
Given $n+1$ uniformly distributed points with $n$ even and $n \geq 2$ 
\begin{equation}\nonumber
    a=x_0<x_1<x_2<\dots<x_{n-1}<x_n = b \tx{and} h = \frac{x_{2k}-x_{2k-2}}{2} = x_{2k}-x_{2k-1}\nonumber
\end{equation}
we apply Simpson's method on each subinterval of the form $[x_{2k-2}, x_{2k}]$  for \\$k \in \{1,\dots,\frac{n}{2}\}$ using $x_{2k-1}$ as the midpoint.\\
For a single subinterval we have
\begin{equation}\nonumber
    \int_{x_{2k-2}}^{x_{2k}}f(x)\,dx \approx \frac{h}{3}(f(x_{2k-2}) + 4f(x_{2k-1}) + f(x_{2k}))
\end{equation}
By summing over all the subintervals we get the composite Simpson's rule as
\begin{equation}\label{Simpson's estimator}
    \int_{a}^{b}f(x)\,dx = \sum_{k=1}^{n/2}\int_{x_{2k-2}}^{x_{2k}}f(x)\,dx \approx  \frac{h}{3}\sum_{k=1}^{n/2}(f(x_{2k-2}) + 4f(x_{2k-1}) + f(x_{2k})) =: S_n(f)
\end{equation}

%---------------------------power of simp rule----------------------------------
    
\subsubsection{The power of Simpson's rule}
Recall from Section \ref{Simp_section} that Simpson's rule starts from a second degree polynomial interpolation of the function $f$. Consider the special case when $f$ is itself polynomial of at most second degree. Then by interpolating $f$ as we did in \eqref{second_deg_interpolation} we would get that $q_{a,b}$ is exactly equal to $f$. If this were not the case we could view $f$ as a polynomial interpolation of itself and we would contradict Proposition \ref{uniqueness_of_interp}. In this case, Simpson's rule exactly calculates the integral. Now this seems like a reasonable thing to happen, however what special about this rule is that the same is true for third degree polynomials! This gives rise to the following lemma.
\begin{lemma}\label{power_of_simpson}
   Let $f(x)$ be a polynomial with $deg(f) \leq 3$. Then Simpson's rule comes out to be an equality
    \begin{equation}\nonumber
        S_2(f) = \int_{a}^{b}f(x)\,dx \nonumber
    \end{equation}
\end{lemma}
\begin{proof}
    I have already talked about the case when $deg(f) \leq 2$. Let's focus on $deg(f) = 3$.
    \begin{equation}\nonumber
        f(x) = Cx^3 + g(x) \tx{with} deg(g) \leq 2 \nonumber
    \end{equation}
    Notice that both $I$ and $S_2$ are linear the error becomes
    \begin{equation}\nonumber
        I(f) - S_2(f) = C(I(x^3) - S_2(x^3)) + (I(g) - S_2(g))
    \end{equation}
    By our discussion above $I(g) - S_2(g) = 0$. Let's evaluate $S_2(x^3)$
    \begin{equation}\nonumber
        \begin{split}
            S_2(x^3) & = \frac{b-a}{6}\left(a^3 + 4 \left(\frac{a+b}{2}\right)^3+b^3\right)=\\
            & = \frac{b-a}{6}\left(a^3 + \frac{1}{2} a^3 + \frac{3}{2}a^2b + \frac{3}{2}ab^2 + \frac{1}{2}b^3+b^3\right) = \\
            & = \frac{b-a}{4}(a^3 + a^2b + ab^2 + b^3) = \\
            & = \frac{b^4-a^4}{4}=\\
            & = I(x^3)
        \end{split}
    \end{equation}
    Which gives us that $I(f) - S_2(f) = 0$ concluding the proof.
\end{proof}

%---------------------------Error of simp rule----------------------------------

\subsubsection{Error analysis of Simpson's rule}
One might be tempted to follow a similar reasoning as we did with the trapezoid method; we have three points $a,m,$ and $b$, and starting from \eqref{Err_interpolation} we integrate and get the resulting error. However, due to Lemma \ref{power_of_simpson}, this gives us an answer of 0.
\begin{equation}\nonumber
    I(f) - S_2(f) = \int_{a}^{b}E_2(x)\,dx = \frac{f^{(n+1)}(\xi)}{(n+1)!}\int_{a}^{b}((x-a)(x-m)(x-b))\,dx = 0
\end{equation}
Since
\begin{equation}\nonumber
    \int_{a}^{b}\left((x-a)\left(x-\frac{a+b}{2}\right)(x-b)\right)\,dx = 0
\end{equation}
After having seen Lemma \ref{power_of_simpson} this comes as no surprise, however this means that we have to come up with a better method for deriving the error of Simpson's rule.
\begin{thm}[Error of Simpson's rule]
    Suppose $f \in C^4([a,b])$, then there exists a point $\xi \in [a,b]$ such that
    \begin{equation}\nonumber
        I(f) - S_2(f) = -\frac{(b-a)^5}{2880}f^{(4)}(\xi)
    \end{equation}
\end{thm}
In Simpson's rule we are only given 3 points which means that we can interpolate with a second degree polynomial. As we have already discussed directly computing the error from $E_2(x)$ is of little help. We would like to go up by one degree, that is calculating the error using $E_3(x)$. We only have 3 points at our disposal and ultimately to derive Simpson's rule we only need these. To overcome this we start with 4 points and by taking a limit we end up with only 3.
\begin{proof}
    Let $p_3$ interpolate $f$ at the points $x_0=a, x_1=m-\epsilon, x_2=m+\epsilon,$ and $x_3=b$ with $\epsilon > 0$ a small deviation. By \eqref{Err_interpolation}, for $x \in [a,b]$
    \begin{equation}\nonumber
        f(x) - p_3(x) = E_3(x) = \frac{1}{4!}(x-x_0)(x-x_1)(x-x_2)(x-x_3)f^{(4)}(\eta_x)
    \end{equation}
    for some $\eta_x \in [a,b]$. By Lemma \ref{power_of_simpson} we have that
    \begin{equation}\nonumber
        I(f) - S_2(f) = I(E_3) - S_2(E_3) + I(p_3) - S_2(p_3)=I(E_3) - S_2(E_3)
    \end{equation}
    As $p_3$ is an interpolating polynomial of $f$ we know that at $x=a $ and $x=b$ the error $E_3(x)$ will vanish and so we get
    \begin{equation}\nonumber
        \begin{split}
            S_2(E_3) & = \frac{b-a}{6}(E_3(a) + 4E_3(m) + E_3(b)) =\\
            & = \frac{b-a}{6}(4E_3(m)) = \\
            & = \frac{4(b-a)}{6 * 4!}(m-x_0)(m-x_1)(m-x_2)(m-x_3)f^{(4)}(\eta_m)
        \end{split}
    \end{equation}
    Now by taking the limit as $\epsilon \to 0$ we get that $x_1 \to m$ and $x_2 \to m$. In turn this gives $E_3(m) \to 0$ and so also $S_2(E_3)$ goes to 0. Lastly, by assumption $f \in C^4([a,b])$ implying that
    \begin{equation}\nonumber
        \frac{1}{4!}(x-a)(x-x_1)(x-x_2)(x-b)f^{(4)}(\eta_x)
    \end{equation}
    is continuous on $[a,b]$ and hence can be bounded by a constant function. We can now invoke the Dominated Convergence Theorem \ref{DCT} allowing us to interchange limit and integral. Thus, 
    \begin{equation}\nonumber
        \lim_{\epsilon \to 0}I(E_3) = \frac{1}{4!}\int_{a}^{b}(x-a)(x-m)^2(x-b)f^{(4)}(\eta_x)\,dx
    \end{equation}
    So in the limit we are left with
    \begin{equation}\nonumber
        I(f) - S_2(f) = \frac{1}{4!}\int_{a}^{b}(x-a)(x-m)^2(x-b)f^{(4)}(\eta_x)\,dx
    \end{equation}
    As $(x-a)(x-m)^2(x-b) \leq 0 \quad \forall x \in [a,b]$ we can use Theorem \ref{Gen_IMVT} and for some $\xi \in [a,b]$ we get
    \begin{equation}\nonumber
        I(f) - S_2(f) = \frac{f^{(4)}(\xi)}{4!}\int_{a}^{b}(x-a)(x-m)^2(x-b)\,dx
    \end{equation}
    Computing the integral gives
    \begin{equation}\nonumber
        \int_{a}^{b}(x-a)(x-m)^2(x-b)\,dx = -\frac{(b-a)^5}{120}
    \end{equation}
    So
    \begin{equation}\nonumber
        I(f) - S_2(f) = -\frac{(b-a)^5}{2880}f^{(4)}(\xi)
    \end{equation}
\end{proof}
By applying this theorem to each subinterval one can prove the following theorem.
\begin{thm}[Error of composite Simpson's rule]\label{composite_simp_error}
    Assume we have a uniform grid of $n$ points with grid size $h=\frac{b-a}{n}$ and that $f \in C^4([a,b])$, then for some $\xi \in [a,b]$
    \begin{equation}\nonumber
        I(f) - S_n(f) = -\frac{(b-a)h^4}{180}f^{(4)}(\xi)
    \end{equation}
\end{thm}
Here we clearly see that in fact Simpson's method has error order 4, $O(h^4)$. The remarkable thing about this rule is that we only increase the interpolation degree by one, compared to the trapezoid method, but the error increase by 2 orders!

%---------------------------Example simp rule--------------------------------

\subsubsection{Simpson's example}
Does this theoretical order really hold? With the following simple example we will see that this does in fact occur. We would like to calculate the following integral:
\begin{equation}\nonumber
    \int_{0}^{\pi}e^x\cos(x)\,dx
\end{equation}
Which we how has value $-(e^\pi+1)/2 \approx -12.070346316$. By implementing \eqref{Simpson's estimator} we get the following table.

\begin{center}
    \begin{tabular}{c c c c c}
\toprule
$n$ &         $h$ &       $S_n$ &        Errors & Error ratio \\
\midrule
2 &  1.570796 & -11.592840 &  4.775068e-01 &         N.A \\
4 &  0.785398 & -11.984944 &  8.540230e-02 &    5.591264 \\
8 &  0.392699 & -12.064209 &  6.137359e-03 &   13.915154 \\
16 &  0.196350 & -12.069951 &  3.949931e-04 &   15.537889 \\
32 &  0.098175 & -12.070321 &  2.486034e-05 &   15.888486 \\
64 &  0.049087 & -12.070345 &  1.556458e-06 &   15.972377 \\
128 &  0.024544 & -12.070346 &  9.732054e-08 &    15.99311 \\
256 &  0.012272 & -12.070346 &  6.083193e-09 &   15.998268 \\
512 &  0.006136 & -12.070346 &  3.802132e-10 &   15.999425 \\
1024 &  0.003068 & -12.070346 &  2.376233e-11 &   16.000673 \\
\bottomrule
\end{tabular}
\end{center}

In the table above we compute the integral with Simpson's method doubling $n$ every time. Consequently, this means that $h$ gets halved each time. The third column is the approximate value given by Simpson's method. We see that it gets remarkably close to the correct value. In fact, the error becomes very small for large $n$. Now to compute the order we calculate the ratio using Theorem \ref{composite_simp_error}.
\begin{equation}\nonumber
    \frac{I(f) - S_{n}(f)}{I(f) - S_{2n}(f)} = \frac{(\frac{b-a}{n})^4}{(\frac{b-a}{2n})^4}=16
\end{equation}
By looking at the last column of the table we see that this theoretical convergence does hold.\\
It should be noted that we can easily perform a similar analysis to we did with the trapezoid method in Section \ref{sec_stab_trap_integration}, allowing us to conclude that also Simpson's method for integration is numerically stable.

%--------------Diff vs non diff example for simpson-------
\subsubsection{Simpson's method on Differentiable vs Non-differentiable functions}
Similarly to what we did with the trapezoid method, we can apply Simpson's method to the functions suggested in Example \ref{diff_vs_non_diff}. Plotting the errors for different values of $n$ we get the following plots.

\begin{center}
    \includegraphics[width=\textwidth]{Images/Error of Simpson's integration diff vs non diff.png}
\end{center}

By inspection we notice that, for the differentiable function, Simpson's method needs larger $n$ to stabilize and converge compared to the trapezoid method. Furthermore, Simpson's method has a very hard time approximating the non-differentiable function. Other than the rapid fluctuations we also see that the overall decrease in the error is very slow and still fluctuates for large values of $n$.



%---------------------------Num for oDE----------------------------------
\section{Numerical Methods for Solving Differential Equations}

%---------------------------ODE----------------------------------
\subsection{Ordinary Differential Equations}
To fix some notation, I will denote $x:[a,b] \longrightarrow \R$ the unknown function which we wish to solve for in the differential equation. From now on I will be assuming that $y$ is a function of one variable, commonly denoted $t$, but many concepts can be extended to more general functions. An \textit{ordinary differential equation} is an equation of the form
\begin{equation}\label{ODE}
    \diff{x(t)}{t} = x'(t) = f(t,x(t))
\end{equation}
When solving this differential equation we would find a whole family of functions that satisfy \eqref{ODE}. To have a unique solution we need to pair our ODE with an initial condition.

%---------------------------IVP----------------------------------

\subsubsection{Initial Value Problems}
As the name suggests, an \textit{initial value problem} combines an ODE with a known value $x_{0}$ that our function $x(t)$ takes at some initial time which I denote $t_{0}$. Often in examples I will take $t_{0} = 0$ for simplicity.

\begin{df}[Initial Value Problem]\label{IVP}
Assume that $\, \Omega \subseteq \R^{2}$ is an open set and let $f:\Omega \longrightarrow \R$ be a known function. Define a function $x:[a,b] \longrightarrow \R$ such that $(t,x(t)) \in \Omega$ for all $t \in [a,b]$. An Initial Value Problem is the following:
\begin{equation}\nonumber
    \begin{cases}
        x'(t) = f(t,x(t))\\
        x(t_{0}) = y_{0} 
    \end{cases}
\end{equation}
for some known $t_{0}\in (a,b), x_{0} \in \R$, and $(t_0,x_0) \in \Omega$.
\end{df}
The Picard–Lindel\"{o}f Theorem guarantees the existence and uniqueness of a solution $x$ to an IVP under the assumptions that $f$ is continuous in $t$ and Lipschitz continuous in $x$. For more details see Theorem \ref{picard_thm} and \cite{teschlordinary}. I will be implicitly assuming these assumptions for the rest of the paper so that all the calculations are well-defined.\\
An interesting example of initial value problem is the following. Its importance will be understood once the notion of absolute stability is presented in Section \ref{Abs stability}. 
\begin{ex}\label{ex_1}
Consider the following IVP:
    \begin{equation}\nonumber
    \begin{cases}
        x'(t) = -2x\\
        x(0) = 3 
    \end{cases}
\end{equation}
Which has an exact solution $x(t) = 3 e ^{-2t}$.
\end{ex}


%---------------------------BVP----------------------------------

% \subsection{Boundary Value Problems}
% These problems add a layer of difficulty as we are now talking about a second order differential equation. These problems however constrain the function in a close internal $[t_{0}, t_{1}]$ and provide the values of the function at the end points. Since the differential equation is of second order we need two conditions to fully define the function.

% \begin{df}[Boundary Value Problem]\label{BVP}
% Let $t_{0}, y_{0} \in \R$. Let $f:\R^{2} \longrightarrow \R$ and $y:\R \longrightarrow \R$. A Boundary Value Problem is the following:
% \begin{equation}\nonumber
%     \begin{cases}
%         y''(t) = f(t,y(t),y'(t)) \quad for \quad t \in [t_{0}, t_{1}]\\
%         y(t_{0}) = y_{0}\\
%         y(t_{1}) = y_{1} \nonumber
%     \end{cases}
% \end{equation}
% Where $t_{0}, t_{1}, y_{0}, y_{1}$ and $f$ are all known and $y(t)$ in unknown.
% \end{df}
% While this definition is general sometimes we will have to impose further assumption on the domain of $y$, for example, so we are guaranteed that a unique solution exists.

Often in numerical analysis it is common practice to discretize time. From now on I will assume that we discretize time uniformly with step size $h$.
\begin{equation}\nonumber
    t_n := a + n h \tx{for} n \in \left\{0, \,\dots , \left\lfloor \frac{b-a}{h} \right\rfloor\right\}
\end{equation}
For clarity, I will set $x_n := x(t_n) = x(a + n h)$ and I will denote $y_n$ as the approximation of $x_n$ given by a numerical method.\\

We are finally ready to talk about numerical methods for ordinary differential equations. These become more complex numerical method compared to integration since an error in the beginning may lead to a much bigger error further down the line. For this reason, the stability analysis becomes more important and complicated than before. We start with the Euler methods with are the easiest and simplest methods for solving IVPs.

%----------------euler methods for IVP--------------
\subsection{Euler methods}
\textbf{Explicit Euler}: The relation of the explicit Euler method is as follows
\begin{equation}\nonumber
    y_{n+1} = y_n + h f(t_n, y_n), \quad y_0 = x_0
\end{equation}
TODO: trunction error

\textbf{Implicit Euler}: The implicit Euler method is similar to the previous with a slight variation
\begin{equation}\nonumber
    y_{n+1} = y_n + h f(t_{n+1}, y_{n+1}), \quad y_0 = x_0
\end{equation}

TODO: trunction error
%----------------trap method for IVP--------------
\subsection{Trapezoidal Method}
Recalling  equation \eqref{Integral_ODE}, by discretizing time we have that at time $t_{n+1}$
\begin{equation}\nonumber
    x_{n+1} = x_n + \int_{t_n}^{t_{n+1}}f(s,x(s))\,ds
\end{equation}
Now applying $T_1(f)$ from equation \eqref{def_trap_single_interval} to the integral
\begin{equation}\label{trap_method_for_ode}
    y_{n+1} = y_n + \frac{1}{2}h(f(t_n, y_n) + f(t_{n+1}, y_{n+1})) \tx{and} y_0 = x_0
\end{equation}
Now we have a way of calculating the next value of $x$ given the current point. When applying this method one usually computes the value for many steps to get an idea of the shape of the unknown function. Lucky for us, we have already done all the calculation needed to calculate the truncation error in Theorem \ref{thm_trap_error_1_interval} and we get that, for all $n>0$, there exists some $\xi_n \in [a,b]$
\begin{equation}\nonumber
    E_{t_n}^{Trap} = -\frac{1}{12}h^3f''(\xi_n,x(\xi_n)) = -\frac{1}{12}h^3x'''(\xi_n)
\end{equation}
This truncation error is the error of a single step and it turns out to be of order $O(h^3)$. When a method has truncation error of order $p+1$ (i.e. $O(h^{p+1})$) then we say that the method is of order $p$ since, under regularity assumptions, Theorem \ref{convergence_with_zero_stability} states that the global error will be of order $p$. In this case the trapezoid method is of order 2. 
As we can see from \eqref{trap_method_for_ode} this is an implicit method, that is, to find the value of $y_{n+1}$ we must solve an equation. Depending on $f$ this is easier said than done, and the method we use to solve the equation might have an impact on the accuracy of our numerical solution. This will be discussed further in Section \ref{discussion_trap}.\\
{\color{white}-}\\
To illustrate the trapezoid method at work we can apply it to Example \ref{ex_1} and we get the following plot.
\vspace{-2.5mm}
\begin{center}
    \includegraphics[width=0.8\textwidth]{Images/Trap example 1.png}
\end{center} 



%---------------------------Adams-bashforth----------------------------------

\subsection{Adams-Bashforth Method}
It has become common practice in this paper to start deriving numerical methods starting from a polynomial interpolation. This method is no exception. The derivation of the Adams-Bashforth method is reminiscent of what we did for the trapezoid method and in fact there is a derivation starting from the trapezoid method. Nevertheless, I will again start from polynomial interpolation.

We first discretize time into many steps of size $h$. Then, for ease, of notation set $g(t) = f(t,x(t))$ and take the interpolating polynomial of $g$ at the points $t_{n-1}$ and $t_n$
\begin{equation}\nonumber
    p(x) = \frac{x-t_{n-1}}{t_n-t_{n-1}} g(t_n) + \frac{t_n-x}{t_n-t_{n-1}} g(t_{n-1})
\end{equation}
Where this derivation differs compared to that of the trapezoid method is that we now integrate over $[t_n,t_{n+1}]$ as opposed to $[t_{n-1},t_{n}]$. As $p(x)$ interpolates $g$ we get the following approximation
\begin{equation}\nonumber
    \int_{t_n}^{t_{n+1}}g(s)\,ds \approx \int_{t_n}^{t_{n+1}}p(s)\,ds
\end{equation}
By direct computations we get that the integral of the interpolating polynomial is
\begin{equation}\nonumber
    AB(g) := \int_{t_n}^{t_{n+1}}p(s)\,ds = \frac{h}{2}(3g(t_n) - g(t_{n-1}))
\end{equation}
To find the truncation error we again start from Theorem \ref{Err_interpolation_thm}.
\begin{equation}\nonumber
    E_{t_n}^{AB} := \int_{t_n}^{t_{n+1}}g(s)\,ds - \int_{t_n}^{t_{n+1}}p(s)\,ds = \int_{t_n}^{t_{n+1}}\frac{g''(\eta_s)}{2}(s-t_{n-1})(s-t_n)\,ds
\end{equation}
Then using Theorem \ref{Gen_IMVT} and computation, for some $\xi_n \in [t_{n},t_{n+1}] $
\begin{equation}\nonumber
    \begin{split}
        \int_{t_n}^{t_{n+1}}\frac{g''(\eta_s)}{2}(s-t_{n-1})(s-t_n)\,ds & = \frac{g''(\xi_n)}{12}(t_{n+1} - t_n)^2(t_n + 2t_{n+1} - 3t_{n-1})=\\ & = \frac{5}{12}h^3g''(\xi_n)
    \end{split}
\end{equation}

This indicates that the Adams-Bashforth method has truncation error of order 3, $O(h^3)$ and so is of second order.
Starting from \eqref{Integral_ODE} and recalling that $g(t) = f(t, y)$ we get
\begin{equation}\label{AB_method}
    y_{n+1} = y_n + \frac{1}{2}h(3f(t_n, y_n) - f(t_{n-1}, y_{n-1})) \tx{and} y(t_0) = y_0
\end{equation}
To start the recursion we also need $y_1$. The simplest way to do this is to use Euler's method to give the first value.
If we try and apply this method to Example \ref{ex_1} we get
\vspace{-2.5mm}
\begin{center}
    \includegraphics[width=0.8\textwidth]{Images/AB example 1.png}
\end{center} 

%---------------------------Runge-Kutta----------------------------------


\subsection{Runge-Kutta of fourth order (RK4)}\label{Runge_kutta_sec}
%https://lpsa.swarthmore.edu/NumInt/NumIntFourth.html
The Runge-Kutta methods are of a whole family of methods, nonetheless I will only present the Runge-Kutta method of fourth degree which is the most popular. I will not however present the derivation and jump immediately to the analysis.
The method is best written as
\begin{align}\nonumber
    k_1 &= f(t_n,y_n)\\ \nonumber
    k_2 &= f(t_n+\frac{1}{2}h,y_n+k_1\frac{h}{2})\\\nonumber
    k_3 &= f(t_n+\frac{1}{2}h,y_n+k_2\frac{h}{2})\\\nonumber
    k_4 &= f(t_n+h,y_n+k_3h)\\\nonumber
    y_{n+1} &= y_n + \frac{h}{6}(k_1 + 2k_2 + 2k_3 + k_4)
\end{align}
For a more intuitive description, let's understand what the various $k$'s mean.
\begin{itemize}
    \item $k_1$ is the slope at the start of time step $n+1$ (equal to the slope at the end of time step $n$).
    \item Following the slope give by $k_1$ but only taking half a step, we then recalculate the slope at this midpoint and we get $k_2$.
    \item Now if we go back to the start of the time step and take half a step following the slope given by $k_2$ and recalculate again the slope at this point we get $k_3$.
    \item Lastly we take a complete step following the slope given by $k_3$ and the slope at that final point is exactly $k_4$.
    \item Taking inspiration from Simpson's method for approximating integrals we get the last equation.
\end{itemize}
The last point justifies the fact that this method, like Simpson's method in Section \ref{Simp_section}, has a truncation error of fifth order $O(h^5)$, and so is considered of fourth order.\\
The last equation can also be seen as a weighted average of the slopes that we calculated in the previous steps. With this perspective in mind, we notice that the slope at the middle points, denoted $k_2$ and $k_3$, have a higher weight compared to the other two slopes. If we go back to the derivation of Simpson's method we can see why this would be the case. When we interpolate the function $f$, by construction the interpolant agrees exactly with the function at the midpoint and the extrema of the subinterval. If the subinterval is small enough and the function is sufficiently smooth it wouldn't be so far-fetched to say that the slopes of $f$ and the polynomial are similar at the midpoint. This comes from the fact that the function cannot vary too drastically inside the subinterval we are considering because of the regularity we are assuming. Furthermore, at the extrema even though the function and the polynomial start at the same point, they may have very different slopes because in the interpolation over a single subinterval we do not consider any information we have about the function outside the subinterval. Actually, using spline interpolation there is no guarantee that we can even differentiate the interpolating polynomial at the extrema of the subinterval. The Jupyter Notebook in \cite{Barbiere_Numerical_Method_for} illustrates an example of this.

When we apply Example \ref{ex_1} to RK4 we are left with the following plot

\vspace{-2.5mm}
\begin{center}
    \includegraphics[width=0.8\textwidth]{Images/RK4 example 1.png}
\end{center}  
%Adavnateges and disadavntages: https://testbook.com/maths/runge-kutta-4th-order

%---------------------------Stability analysis LMM-----------------------------
%https://epubs.siam.org/doi/book/10.1137/1.9780898717839


\section{Stability Analysis of Linear Multistep methods}
Most of the methods we have seen thus far are all examples of linear multistep methods with the only exception being the Runge-Kutta method. This is an important distinction to make as it affects how we perform the stability analysis. In this section I will focus on linear multistep methods, therefore all the definition will be tailored to these kinds of methods. Nevertheless, all the derivations and explanations behind the definitions are presented in such a way that they can easily be adapted to other types of methods. We will see this in actions when we analyse the Runge-Kutta method in Section \ref{RK4_stab_sec}.

{\color{white}-}\\
A general \textit{r-step linear multistep method} is a method of the form
\begin{equation}\label{LMM}
    \sum_{j=0}^r\alpha_jy_{n+j} = h\sum_{j=0}^r\beta_jf(t_{n+j}, y_{n+j})
\end{equation}
Notice that the trapezoidal method and the second order Adams-Bashforth method are both particular cases of this general equation. To get the trapezoidal method in equation \eqref{trap_method_for_ode} we choose
\begin{equation}\label{trap_parameters}
    r=1,\quad \alpha_0 = -1,\quad \alpha_1 = 1 \tx{and} \beta_0 = \beta_1 = \frac{1}{2}
\end{equation}
To get Adams-Bashforth seen in equation \eqref{AB_method}, with a slight change of indexing, we must set
\begin{equation}\label{AB_parameters}
    r=2,\quad \alpha_0 = 0,\quad \alpha_1 = -1, \quad \alpha_2 = 1, \quad \beta_0 =-\frac{1}{2}, \quad \beta_1 = \frac{3}{2} \tx{and} \beta_2 = 0
\end{equation}

%---------------------------global and local trunc error------------------------------

\subsection{Global and Local truncation error}
To start analysing the stability of linear multistep methods we first want to quantify the error our methods make. Errors are inevitable when we try to approximate an analytical solution, however we would like to make sure that these errors remain under control and go to zero as our step size goes to zero.
The first type of error we are interested in is the \textit{global (truncation) error} which is defined as the exact solution minus the numerical approximation
\begin{equation}\nonumber
    e_n := x(t_n) - y_n
\end{equation}
This notion is important as it leads to the definition of \textit{convergence}.
\begin{df}[Convergence]
    We say a numerical method is convergent if, for every initial value problem \eqref{IVP},
    \begin{equation}
        e_n = y(t_n) - y_n \to 0 \tx{as} h \to 0 \tx{for all} t_n \in [a, b]
    \end{equation}
\end{df}
Notice that this definition is not restricted to linear multistep methods and is valid for general numerical methods.\\
Next the \textit{local truncation error} for linear multistep methods is defined\footnote{The definition of local truncation error may vary between reference texts. We use this definition to remain consistent with the truncation error used thus far.} as the following
\begin{equation}\nonumber
    \tau(t_{n+r}) := \sum_{j=0}^r\alpha_jx(t_{n+j}) - h\sum_{j=0}^r\beta_jx'(t_{n+j})
\end{equation}
We will see the relation between local and global truncation error in Theorem \ref{convergence_with_zero_stability}.
Assuming that $x(t)$ is smooth enough we can take the Taylor series of $x(t)$ and $x'(t)$
\begin{align}\nonumber
    x(t_{n+j}) & = x(t_n) + jkx'(t_n) + \frac{1}{2}(jk)^2x''(t_n)+\dots\\
    x'(t_{n+j}) & = x'(t_n) + jkx''(t_n) + \frac{1}{2}(jk)^2x'''(t_n)+\dots \nonumber
\end{align}
Substituting this back into the local truncation error gives
\begin{align}\label{trunc_approx}
    \tau(t_{n+r}) & = \left(\sum_{j=0}^r\alpha_j\right)x(t_n) + h\left(\sum_{j=0}^r(j\alpha_j-\beta_j)\right)x'(t_n) + \\&+ h^2\left(\sum_{j=0}^r\left(\frac{1}{2}j^2\alpha_j - j\beta_j\right)\right)x''(t_n) + o(h^2) \nonumber
\end{align}
\begin{df}[Consistent method]
    We call a numerical method \text{consistent} if $\tau(t) = o(h)$ for all $t \in [a,b]$ that is, 
    \begin{equation}\nonumber
        \frac{\tau(t)}{h} \to 0 \tx{as} h \to 0 \quad \forall t \in [a,b]
    \end{equation}
\end{df}
 From \eqref{trunc_approx} we see that for consistency to hold we must have that
\begin{equation}\label{consistent_conditions_summation}
    \sum_{j=0}^r\alpha_j=0 \tx{and} \sum_{j=0}^rj\alpha_j=\sum_{j=0}^r\beta_j
\end{equation}
By further expanding \eqref{trunc_approx} we can set the coefficients of higher powers of $h$ to 0, and in so doing, we will be left with a system of equations which we can use to solve for the coefficients $\alpha_i$ and $\beta_i$ for $i\in\{0,\dots,r\}$. As a consequence the local truncation error will be of higher order and by Theorem \ref{convergence_with_zero_stability} also the global error will be of higher order. A derivation of higher order Adams-Bashforth methods using this approach can be found in \cite{butcher2016numerical}.\\
An important observation is that the consistency conditions \eqref{consistent_conditions_summation} only depend on the method and not the actual IVP we are solving. Hence, they hold for any initial value problem we may tackle.  

%---------------------------Char polynomial--------------------------------

\subsection{Characteristic polynomials}
For linear multistep methods it is useful to define the two following polynomials called \textit{characteristic polynomials}.
\begin{equation}\nonumber
    \rho(\zeta):=\sum_{j=0}^r\alpha_j\zeta^j \tx{and} \sigma(\zeta):=\sum_{j=0}^r\beta_j\zeta^j
\end{equation}
With these definitions in mind we can rewrite the consistency conditions as
\begin{equation}\label{consistent_conditions}
    \rho(1)=0 \tx{and} \rho'(1)=\sigma(1)
\end{equation}

%---------------------------zero-stability---------------------------------

\subsection{Zero-stability of a linear multistep method}\label{zero_stab_section}

The next step is introducing the notion of \textit{zero-stability}. This is one of many different notions of stability for numerical methods one can look at. It is very simple but nonetheless very impactful thanks to Theorem \ref{convergence_with_zero_stability}.

To get some intuition behind zero-stability, let's look at the simplest example of IVP. 
\begin{ex}\label{zero_stab_example} Consider this IVP:\quad
    $x'(t) = 0 \tx{with} x(0)=0$
\end{ex}
The obvious solution of this is $x(t) = 0$, but there are many methods that fail to reach this solution given a small initialization error. The next examples will illustrate this very well.

Take the following linear multistep method trying to solve Example \ref{zero_stab_example}.
\begin{equation}\label{bad_multistep}
    y_{n+2} - 3y_{n+1} + 2y_n = 0, \quad \quad y_0 = 0
\end{equation}
While there is so real justification why someone would use this method, it seems like a perfectly reasonable 2-step linear multistep method. To start the recurrence we need to estimate $y_1$. Assume that in doing so we get that $y_1 = \varepsilon \neq 0$. With methods we will explore soon, one can solve \eqref{bad_multistep} for $y_n$ starting from $y_1$ and $y_0$ giving
\begin{equation}\nonumber
    y_n = 2y_0 - y_1 + 2^n(y_1 - y_0)
\end{equation}
Under our assumption of $y_1 = \varepsilon$ we are left with
\begin{equation}\nonumber
    y_n =  (2^n - 1)\varepsilon
\end{equation}
Which obviously diverges as $n \to \infty$.\\
Why did this happen? Well in general it comes down to solving the linear equation
\begin{equation}\label{difference_equation}
    \sum_{j=0}^r\alpha_jy_{n+j} = 0
\end{equation}
As $y_{n+j}$ depends on the previous $y_i$ for $i \in \{n, \dots, n+j-1\}$ a reasonable guess for a solution would be 
\begin{equation}\nonumber
    y_{n+j} = k^{n+j}
\end{equation}
For some value of $k \in \R$. For this to happen $k$ must satisfy
\begin{equation}\nonumber
    \sum_{j=0}^r\alpha_jk^{n+j} = 0
\end{equation}
which is exactly like saying that $k$ must be a root of $\rho(\zeta)$. What's more, by the Fundamental Theorem of Algebra $\rho(\zeta)$ must have $r$ roots and as \eqref{difference_equation} is linear, the general solution is 
\begin{equation}\nonumber
    y_n = \sum_{j=1}^rc_j\zeta_j^{n}
\end{equation}
where $\zeta_j$ for $j = 1,\dots,r$ are the roots of $\rho(\zeta)$. To solve for the coefficients we must use the initial conditions. To start the recurrence we need $r$ initial conditions so we have enough starting information to solve for the $r$ coefficients which leaves us with a $r \times r$ system of equations.
A first idea of stability could be imposing that $y_n$ should not diverge as $n \to \infty$. For this be to fulfilled we must have that $|\zeta_j| \leq 1$ for all the roots. There is a slight catch if the roots repeat as the system to solve for the initial conditions becomes singular and so we must impose that $|\zeta_j| < 1$ if $\zeta_j$ is a repeated root to mend this. A more precise explanation of this may be found at \cite{leveque2007finite}.

All of this reasoning is the motivation for defining zero-stability.
\begin{df}[zero-stability for linear multistep methods]
    A r-step linear multistep method is said to be zero-stable if the roots of the characteristic polynomial $\rho(\zeta)$ denoted $\zeta_1, \dots , \zeta_r$ satisfy the following conditions:
    \begin{align}
        &|\zeta_j| \leq 1 \tx{for} j=1,\dots,r\\
        & \text{If} \,\zeta_j \,\text{is a repeated root, then} \,|\zeta_j| < 1   
    \end{align}
\end{df}
The discussion above conveys the intuition behind zero-stability: we say that a numerical method is zero-stable if, given an slight perturbation of the initial condition of Example \ref{zero_stab_example}, $y_n$ does not diverge as $n \to \infty$ (equivalently $h \to 0$).
This important definition as it leads to the following theorem.
\begin{thm}[Dahlquist’s Equivalence Theorem]\label{convergence_with_zero_stability}
    Given a linear multistep method used to solve an initial value problem as in Definition \ref{IVP}, under the assumptions of the Picard–Lindel\"{o}f Theorem \eqref{picard_thm} we have that:
    \begin{equation}\nonumber
        \text{consistency} \quad + \quad\text{zero stability} \quad \iff \quad\text{convergence}
    \end{equation}

Moreover, if the solution $x \in C^{\,p+1}([a,b])$ and local truncation error is of order $O(h^{p+1})$ then the global error if of order $O(h^p)$.
\end{thm}

\begin{proof}
    The proof of this theorem can be found in \cite{gautschi2011numerical}
\end{proof}
% \begin{proof}
% %see suli and mayers book
%     The proof of this result is long and technical; for details of the argument, see Theorem 6.3.4 on page 357 of W. Gautschi, Numerical Analysis: an Introduction, Birkh¨auser, Boston, MA, 1997, or Theorem 5.10
% on page 244 of P. Henrici, Discrete Variable Me
% \end{proof}

This theorem provides theoretical guarantees that for $h$ small enough and if the method is consistent we will converge to the correct result, which is as good as we would have hope for numerical methods. Let's apply our theory to some numerical methods to see if they eventually converge to the correct result.
{\color{white}-}\\
Zero-stability however is not the only kind of stability we care about. In fact often this stability is not useful. These condition basically tell us that "eventually" for $h$ small enough we will be very close to the exact answer. How small does $h$ have to be for us to be arbitrarily close to the correct value? Actually, it can also happen that for values of $h$ not small enough the error is extremely large. Essentially there are no guarantees that a given $h$ will give a small error. To dive deeper into stability analysis we will introduce absolute stability.

%---------------------------Abs stability-------------------------------

\subsection{Absolute stability for multistep methods}\label{Abs stability}
This notion of stability focuses on a specific linear example of ODE. We will call this the \textit{test equation}.
\begin{equation} \label{test_ODE}
    x'(t) = \lambda x(t) 
\end{equation}
While this equation seems extremely simple, by varying $\lambda$ we can really put to the test many of the methods we have seen. If we take one step further we can even take $\lambda$ to be complex allowing us to visualize regions of absolute stability in the complex plane. Why do we care so much about equation \eqref{test_ODE} which has a very simple solution $Ce^{\lambda t}$? Firstly, it can be generalized to include linear system of differential equations. In this case all we have to do is calculate the eigenvalues of the matrix representing the system and we can apply absolute stability to each eigenvalue in order to conclude absolute stability over the whole system. Actually it can be even generalized to non-linear systems, by taking a linear approximation of the function and applying the same idea as for linear system of differential equations. The second reason for its importance is that this is the simplest example of what's called a stiff differential equation. A stiff differential equation causes many numerical methods to behave unstably if $h$ is not chosen small enough. If, for example, we take $\lambda$ to be very large, then the step the numerical method makes is multiplied by $\lambda$ and might lead to the numerical method overshooting the real value. This is clearly seen in  Example \ref{ex_1} applied to AB2 when $h = 0.5$. So the numerical method will have a hard time converging to the correct result. We notice that this can be mitigated by choosing $h$ small enough so to counteract the impact $\lambda$ has on the method.
For example applying the explicit Euler method to \eqref{test_ODE} gives
\begin{equation}\label{euler_abs_stab}
    y_{n+1} = (1+h\lambda)y_n
\end{equation}
For the explicit Euler method to be absolutely stable we must have that $|1+h\lambda|\leq 1$. Note that while $\lambda$ is complex we still take $h$ to be real. It is evident that the important aspect here is the product of $h$ and $\lambda$. This is perfectly inline with what we discussed above since taking $h$ small can reduce the effect of $\lambda$. So the important aspect to monitor is the product $\lambda h$ and it is precisely this that we are going to plot to find what is called the \textit{absolute stability regions} of the numerical methods.\\
In the explicit Euler the stability region comes out to be a circle of radius 1 centred at $(-1,0)$ as we can see in Section \ref{particular case euler section}.\\


%---------------------------Abs stability for LMM-------------------------------

Using \eqref{LMM} to solve our test problem and rearranging we obtain
\begin{equation}\label{difference_equation_abs_stab}
    \sum_{j=0}^r(\alpha_j -  h \lambda\beta_j)\, y_{n+j} = 0
\end{equation}
Similar to the previous example, the important parameter to consider is the product of $h$ and $\lambda$. Setting $z=h\lambda$ we define the stability polynomial defined as
\begin{equation}\nonumber
    \pi(\zeta;z)=\rho(\zeta)-z\sigma(\zeta)
\end{equation}
Where $\pi(\zeta;z)$ is a polynomial in $\zeta$ whose coefficients depend on $z$. The essential point in this argument is that equation \eqref{difference_equation_abs_stab} is identical to equation \eqref{difference_equation} with slightly different coefficients. Using the exact argument we did in Section \ref{zero_stab_section} with $\pi(\zeta;z)$ instead of $\rho(\zeta)$ we get another kind of stability: \textit{Absolute stability}.
\begin{df}[Absolute stability]
    A r-step linear multistep method is said to be absolutely stable if the roots of the stability polynomial $\pi(\zeta;z)$ denoted $\zeta_1, \dots , \zeta_r$ satisfy the following conditions:
    \begin{align}
        &|\zeta_j| \leq 1 \tx{for} j=1,\dots,r\\
        & \text{If} \,\zeta_j \,\text{is a repeated root, then} \,|\zeta_j| < 1   
    \end{align}
\end{df}
We are now ready to plot some stability regions of some numerical methods.


%---------------------------euler method case-------------------------------
\subsection{Particular case: Euler Methods}\label{particular case euler section}
The explicit and implicit Euler methods are one of the simplest linear multistep methods there is.\\
{\color{white}-}\\
\textbf{Explicit Euler}:
This formula gives rise to the following characteristic polynomials
\begin{equation}\label{char_poly_exp_ee}
    \rho_{EE}(\zeta) = -1 + \zeta \tx{and} \sigma_{EE}(\zeta) = 1
\end{equation}
Where $\rho_{EE}(\zeta)$ has a single root namely $\zeta_1=1$. As the conditions \eqref{consistent_conditions} are satisfied we conclude that the explicit Euler method is zero-stable and consistent which, by the previous theorem, is equivalent to being convergent.\\
{\color{white}-}\\
\textbf{Implicit Euler}: 
Which has the following characteristic polynomials
\begin{equation}\label{char_poly_exp_ie}
    \rho_{IE}(\zeta) = -1 + \zeta \tx{and} \sigma_{IE}(\zeta) = \zeta
\end{equation}
Where $\rho_{IE}(\zeta)$ has a single root $\zeta_1=1$. Similarly to the explicit Euler method also the implicit Euler is zero-stable and consistent, which is to say convergent.\\

We have already seen the derivation for the stability region of the explicit Euler method. Deriving the implicit Euler method stability region is very similar.\\
\begin{minipage}[b]{.5\textwidth}
    \includegraphics[width=\textwidth]{Images/Stab region of Explicit Euler.png}
\end{minipage}%
\begin{minipage}[b]{.5\textwidth}
    \includegraphics[width=\textwidth]{Images/Stab region of Implicit Euler.png}
\end{minipage}%

\subsubsection{Discussion of the Euler methods}
Euler methods come out naturally from approximating the derivative using the difference quotient which implies that they are as simple as one can get. Their simplicity means that it takes very little computational power to run as we are only calling the function once (which might become be expensive for complicated functions) and performing basic operations. This simplicity however comes at a cost of instability. Just by looking at the stability region of the explicit Euler method. This means that $h$ must be chosen very well to avoid instability and often $h$ might have to be so small that the number of computations needed to become too large. Often computers have trouble dealing with very small numbers as this will likely lead to floating point number approximations.
{\color{white}-}\\
Backwards Euler on the other hand does not suffer from a small stability region, however slow convergence and the high chance of low accuracy remain very prominent issues. Furthermore, it is an implicit method which comes with some serious drawback as we shall see in the discussion of the trapezoidal method, Section \ref{discussion_trap}.

%---------------------------trap method case-------------------------------

\subsection{Particular case: Trapezoidal method for IVPs}
From \eqref{trap_parameters} we clearly see that the trapezoidal method is a consistent method. Now to check if the method is zero-stable let's first find it's characteristic polynomials.
\begin{equation}\label{char_poly_trap}
    \rho_{T}(\zeta) = -1 + \zeta \tx{and} \sigma_T(\zeta) = \frac{1}{2} + \frac{1}{2}\zeta
\end{equation}
Where $\rho_{T}(\zeta)$ and has root $\zeta_1=1$. With these characteristic polynomials in mind we can easily state that the trapezoidal method is both zero-stable and consistent, and so convergent.\\
From the characteristic polynomials found in \eqref{char_poly_trap} we have that the stability polynomial
\begin{equation}\nonumber
    \pi_T(\zeta;z) = -\left(1+\frac{1}{2}z\right) + \left(1-\frac{1}{2}z\right)\zeta
\end{equation}
has a single root, which is
\begin{equation}\nonumber
    \zeta_1 = \frac{1+\frac{1}{2}z}{1-\frac{1}{2}z}
\end{equation}
and taking the absolute value we get
\begin{equation}\nonumber
    |\zeta_1| \leq 1 \iff \left|1 + \frac{1}{2}z \right| \leq \left|1-\frac{1}{2}z \right| \iff \left|2 + z \right| \leq \left|2-z \right|
\end{equation}
which is like saying all the complex numbers $z$ that are closer to $-2$ than to $2$, giving us the left half plane as below.
\vspace{-2.5mm}
\begin{center}
    \includegraphics[width=0.5\textwidth]{Images/Stab region of Trapezoidal Method.png}
\end{center}  

\subsubsection{Discussion of the Trapezoidal method}\label{discussion_trap}
The trapezoidal method that came directly from the trapezoid method for numerical integration. The remarkable property of this method is the fact that its stability region is the half plane. It turns out that it is impossible to have an explicit method with this property and what's more the only linear multistep method that achieves this must have order at most 2. The trapezoidal method turns out to be the most accurate among all of these. The most evident problem of this method however is the fact that we need to solve an equation (that depends on f) to implement the step. Solving equations numerically is a whole other branch of numerical analysis, however all we really care about it that solving equations numerically may bring with them error that were not accounted for in the analysis of the trapezoidal method. Furthermore, implicit methods also need more initial points to start the calculation. Often this is done by using very simple methods to get the first few points such as the Euler methods. The problem is that this may lead to possible errors in the starting conditions, which is obviously not ideal. Luckily we introduced zero-stability to make sure this error does not explode, but still errors in the starting conditions may propagate through the steps and end up hurting our final accuracy.

%---------------------------Ab case----------------------------------
\subsection{Particular case: Adams-Bashforth}
Similarly to the trapezoidal method, also Adams-Bashforth is consistent. Furthermore, its polynomial is
\begin{equation}\nonumber
    \rho_{AB}(\zeta) = -\zeta + \zeta^2 \tx{and} \sigma_{AB}(\zeta) = -\frac{1}{2} + \frac{3}{2}\zeta
\end{equation}
Since $\rho_{AB}(\zeta)$ has two roots $\zeta_1 = 0$ and $\zeta_2 = 1$ we conclude that also this method is convergent.\\
The stability polynomial of the Adams-Bashforth method of order 2 is
\begin{equation}\nonumber
    \pi_{AB}(\zeta;z) =  \frac{1}{2}z + \left(-\frac{3}{2}z-1\right)\zeta + \zeta^2
\end{equation}

In this case checking the root condition may become complicated, and more so for higher orders. In this case we can resort to the computer programs which display the region of stability of the various methods. Thanks to the construction of the stability polynomial it is very easy to generalize the program to Adams-Bashforth of any order. Below I illustrate the stability regions for the Adams-Bashforth methods up to order 5.\\
\begin{minipage}[b]{.5\textwidth}
    \includegraphics[width=\textwidth]{Images/Stab region of AB2.png}
\end{minipage}%
\begin{minipage}[b]{.5\textwidth}
    \includegraphics[width=\textwidth]{Images/Stab region of AB Methods.png}
\end{minipage}%

\subsubsection{Discussion of the Adams-Bathforth method}
After having slightly varied the derivation of the trapezoidal method we discovered another method: Adams-Bashforth (which actually belongs to a whole family of methods). This method is particularly interesting as it only uses one extra function call to gain compared to the explicit Euler method, but the improvement is quite substantial. Despite this if we try to use higher order AB methods we see that the stability region becomes extremely small leading to a very high chance of instability.


%-----------------Stab analyis of RK4----------------------
\section{Stability Analysis of Runge-Kutta of fourth order}\label{RK4_stab_sec}
We now move on to the stability of the Runge-Kutta of fourth order. Here I present the derivation only for the fourth order method, but the reasoning can be generalized. The ideas behind zero-stability and absolute stability are carried over also to this method but we need a slightly different approach. For example, it is clear from Section \ref{Runge_kutta_sec} that if we apply the RK4 method to the differential equation behind the definition of zero-stability (Example \ref{zero_stab_example}) we observe that we get the correct solution with no chance of diverging, so the RK4 method is trivially zero-stable.

In the footsteps of absolute stability for multistep methods, we will also apply RK4 to the differential equation defined as
\begin{equation}\label{test_ODE_abs_stab}
    x'(t) = \lambda x(t)
\end{equation}
By direct computation we get the following values for $k_1$, $k_2$, $k_3$, and $k_4$.
\begin{align}
    k_1 &= \lambda y_n\\ \nonumber
    k_2 &= y_n \left(\lambda + \frac{\lambda^2 h}{2} \right)\\ \nonumber
    k_3 &= y_n \left(\lambda + \frac{\lambda^2 h}{2} + \frac{\lambda^3 h^2}{4} \right)\\ \nonumber
    k_4 &= y_n \left(\lambda + \lambda^2 h + \frac{\lambda^3 h^2}{2} + \frac{\lambda^4 h^3}{4} \right) \nonumber
\end{align}
Putting everything together we get the value of $y_{n+1}$.
\begin{equation}\nonumber
    y_{n+1} = y_n \left[1 + \lambda h + \frac{(\lambda h)^2}{2} + \frac{(\lambda h)^3}{6} + \frac{(\lambda h)^4}{24} \right]
\end{equation}
The spectacular part about this is that the multiplicative coefficient of $y_n$ is exactly the fourth order Taylor expansion of $e^{\lambda h}$ which, up to a multiplicative constant, is the correct solution to \eqref{test_ODE_abs_stab}. \\
Using $z = \lambda h $ as above, let us define
\begin{equation}\nonumber
    R(z) := 1 + z + \frac{z^2}{2!} + \frac{z^3}{3!} + \frac{z^4}{4!}
\end{equation}
Similarly to how we analysed the absolute stability of the explicit Euler method in equation \eqref{euler_abs_stab}, for the RK4 method to be absolutely stable we need that the coefficient of $y_n$ does not blow up to infinity, which is to say $|R(z)| \leq 1$. Plotting this inequality similarly to what we did with the other methods results in the following graph.

\begin{minipage}[b]{.5\textwidth}
    \includegraphics[width=\textwidth]{Images/Stab region of RK4.png}
\end{minipage}%
\begin{minipage}[b]{.5\textwidth}
    \includegraphics[width=\textwidth]{Images/Stab region of RK Methods.png}
\end{minipage}%


\subsection{Discussion of Runge-Kutta of fourth order}
The RK4 method is a very good compromise between complexity and stability is the fourth order Runge-Kutta method. We can see that this method performs remarkably well in many examples and, taking special care in noticing the scale of the axes we observe that the RK4 method has a very large stability region. Moreover, we notice that in fact the stability regions gets bigger as we increase the order of the method as we can see in the picture above.  By not being a multistep method there is no need to estimate the first few points which means it is "self-starting". Ultimately what makes it powerful is the fact that it takes the weighted average of various slopes before taking the step. This makes it more robust and helps to lower any errors that may come up from calculating a single slope. All of this obviously comes at a cost. Usually RK4 takes more computational time than multistep method of comparable accuracy and this becomes more evident when we try to solve systems of ODEs. Lastly, the error estimation of the RK methods is quite messy and hard to analysis.

\section{Concluding Remarks}
Throughout this paper I have presented some of the simplest and most common numerical methods for solving ODEs each with its advantages and disadvantages. The reason why there are so many methods is that no method is perfect and ultimately choosing the best method may depend on the problem at hand.
{\color{white}-}\\
After having done of all this analysis a natural question comes up: why don't we use a method of higher order? This seems like a very reasonable question, in fact the stability region of the Runge-Kutta method seems to keep getting bigger, so why don't we just keep increasing the order?
Well the first problem is that it is even very complicated just to come with the methods! Take the Runge-Kutta family for example, even though I did not present the derivation, the formula comes from solving a system of equations. To derive higher order methods the number of equations in the system essentially blows up. For example firth order RK would require sixteen equations. Actually in \cite{Ketcheson_2014} the authors point out that this can only be done efficiently up to order eight. %[Ketcheson and BinWaheed, 2014, p. 178]
Even if it were possible to find any other higher order numerical method they usually become very complicated and harder to implement, which in turn brings with it more computation and so longer run times, not to mention the extremely complicated error analysis that would come with these methods. All of this effort would only bring a slight improvement to the best numerical methods we have so far. In most application often the accuracy of the methods we already have is sufficiently high and increasing the order of methods does not necessarily mean that they would be more stable. Take for example the Adams-Bashforth methods. So in summary, the effort of discovering and implementing higher order methods makes using higher order methods hard to justify.


% Why not increase order?
% tunately, the number of conditional equations rises rapidly with order. We saw that fourth-order
% approximations require eight constraint equations and fifth-order requires sixteen. Order ten approximations require 1, 205 conditions, and order fourteen approximations require 53, 263 conditions!
% Simultaneously solving such highly non-linear systems is complicated for obvious reasons. Ketcheson
% notes this can only be done efficiently up to order eight [Ketcheson and BinWaheed, 2014, p. 178].
% These difficulties force mathematicians to look for other types of numerical methods
% link: %https://digitalcommons.ursinus.edu/cgi/viewcontent.cgi?article=1007&context=triumphs_differ

% Also harder to come up with formulas

% \textbf{Runge-Kutta:
% }
% \textbf{Pros}:
% \begin{itemize}
%     \item easy to implement
%     \item generally quite stable
%     \item get more stable for higher orders
%     \item self starting unlike multistep methods
%     \item RK4 takes a weighted average of the slopes at more number of points than the lower order RK methods, so its a little more expensive, but more accurate compared to lower order RK
% \end{itemize}
% \textbf{Cons}:
% \begin{itemize}
%     \item require significantly more computer time than multi-step methods of comparable accuracy,
%     \item error estimtion
%     \item  can be inefficient for large systems of stiff nonlinear differential equations, especially when stiffness is induced by only a few components (https://typeset.io/questions/what-are-the-advantages-and-disadvantages-of-using-heun-and-4g000k420b)
    
% \end{itemize}

% \textbf{Euler methods:
% }
% \textbf{pros}:
% \begin{itemize}
%     \item Euler’s method requires only one such call, and, that being the case, it’s about as efficient as it can possibly get while still doing the right thing. (https://www.quora.com/Which-method-of-Runge-Kutta-2-or-3-or-4-is-better-and-more-efficient)
%     \item Euler’s method is simple and can be used directly for the non-linear
% IVPs(
% %https://ijaem.net/issue_dcp/Review%20Paper%20on%20Comparative%20Numerical%20Method%20to%20Solve%20Differential%20Equation.pdf)
% \end{itemize}

% \textbf{cons}:
% \begin{itemize}
%     \item numerically unstable
%     \item need a smaller h to get more accurate so more comptutation
% \end{itemize}


% \textbf{Ab methods
% pros} 
% \begin{itemize}
%     \item  it uses only one additional function evaluation per step yet achieves high-order accuracy
    
% \end{itemize}

% \textbf{cons}
% \begin{itemize}
%     \item  necessity of using another method to start
%     \item higher order methods become more unstable
% \end{itemize}


% \textbf{trap pros
% }
% \begin{itemize}
%     \item its stability region is hte half plane (https://arxiv.org/pdf/0810.4965.pdf). In fact it is impossible to have an explciit method with this porperty and whatsmore the only linear multistep method of this have at most error of order 2. the trap method turns out to be the most accurate 
% \end{itemize}


% \section{What's left to do}
% \begin{itemize}
%     \item More numerical example for methods like trapezoid and Adams-Bashforth
%     \item Compare various methods and discuss pros and cons of each one
%     \item discuss the down side of using methods of higher orders
%     \item examples when assumptions are not met\\
% https://webspace.science.uu.nl/~frank011/Classes/numwisk/ch10.pdf
% \item Runge-kutta on system of ODEs ????????\\
% \item other possible example is y' = sin(t) * y
% % (https://ereader.cambridge.org/wr/viewer.html#book/841861b2-b0d6-462e-9b3a-0ba6b5b771ce/page312)
% \end{itemize}



\appendix

\section{Appendix: Supplementary Theorems}

%---------------------------Useful theorems----------------------------------
\begin{thm}[Weierstrass Approximation Theorem]\label{W_approx_thm}
    Suppose $f \in C([a, b])$ is given. For every $\varepsilon > 0$, there exists a polynomial function $p(x)$ such that 
    \begin{equation}\nonumber
        \sup_{x \in [a, b]}|f(x) - p(x)| < \varepsilon
    \end{equation}
    

\end{thm}
\begin{proof}
    \cite{süli2003introduction} presents a proof of this theorem.
\end{proof}

\begin{thm}[Generalized Integral Mean Value Theorem]\label{Gen_IMVT}
    Suppose $f,g:\R \longrightarrow \R$ with $f,g \in C([a,b])$. Furthermore, assume $g$ does not change sign on $[a,b]$. Then there exists a points $\xi \in [a,b]$ such that
    \begin{equation}\nonumber
        \int_{a}^{b}g(x)f(x)\,dx = f(\xi)\int_{a}^{b}g(x)\,dx
    \end{equation}
\end{thm}
\begin{proof}
    This is a generalization of the Integral Mean Value theorem. More details and a proof are discussed in \cite{JE_Book}.
\end{proof}


\begin{thm}[Picard–Lindel\"{o}f]\label{picard_thm}
    Let  $f:\Omega \longrightarrow \R^n$ and suppose $ f \in C(\Omega)$ where $\, \Omega$ is an open subset of $\R^{n+1}$, and $(t_0, x_0) \in \Omega$. If f is locally Lipschitz continuous in the second argument and uniformly continuous with respect to the first, then there exists a unique local solution $x(t) \in C(I)$ of the IVP \eqref{IVP}, where $I$ is some interval around $t_0$.
\end{thm}
\begin{proof}
    The proof can be found in \cite{teschlordinary}.
\end{proof}

\begin{thm}[Dominated convergence theorem]\label{DCT}
    Let $(X, \mathcal{B}, \mu) $ be a measure space, and let $f_1, f_2, \ldots: X \longrightarrow \mathbb{C}$ be a sequence of measurable functions that converge pointwise $\mu$-almost everywhere to a measurable limit $f: X \longrightarrow \mathbb{C}$. Suppose that there is an unsigned absolutely integrable function $G: X \longrightarrow [0, +\infty]$ such that $|f_k|$ are pointwise $\mu$-almost everywhere bounded by $G$ for each $k$. Then we have
    \begin{equation}\nonumber
        \lim_{k \to \infty}\int_{X} f_k \, d\mu = \int_{X}\lim_{k \to \infty}f_k \, d\mu = \int_{X} f \, d\mu
    \end{equation}
\end{thm}
\begin{proof}
    The proof is presented in \cite{tao2011introduction}.
\end{proof}





\newpage

%Removing the need to cite each reference
\nocite{*}
\printbibliography[heading=bibintoc,title={Bibliography}]


\end{document}


%-----------------------------Extra code------------------------

%Linear interpolation error
% \begin{thm}[Linear Interpolation error]
%     Let $f \in C^2([a,b])$ and let $p(x)$ be the linear polynomial that interpolates $f$ at $a$ and $b$. Then, for all $x \in [a,b]$ there exists $\eta_{x} \in [a,b]$ such that
%     \begin{equation}\nonumber
%         f(x) - p(x) = \frac{1}{2}(x-a)(x-b)f''(\eta_{x})
%     \end{equation}
%     Furthermore,
%     \begin{equation}\nonumber
%         |f(x) - p(x)| \leq \frac{1}{8}(b - a)^2 \max_{x \in [a,b]}|f''(x)|
%     \end{equation}
% \end{thm}
% \begin{proof}
%     The proof of this theorem boils down to applying Rolle's Theorem in a clear way. The proof can be found in the book (JE 2013 book).
% \end{proof}


%Example of how to estimate asymptoic behaviour of ometa(x)
% \subsection{Example of asymptotic behaviour of error bound}
% As an example assume we have a uniform grid of n points with grid size $h = \frac{b-a}{n}$. As the (n+1)-th derivative depends on the function we are tackling there is little we can say with certainty. The only real factor we can play with is $\omega(x)$. We notice that $|\omega(x)|$ is largest if $x$ is in one of the end points. This is where the product of the distances is maximized. So if $x \in [x_0, x_1]$ then
% \begin{equation}\nonumber
%     |x-x_j| \leq (j+1)h \tx{for} j \in \{0,\dots,n\} \nonumber
% \end{equation}
% Taking the product give an upper bound for $\omega(x)$
% \begin{equation}\nonumber
%     |\omega(x)| \leq \prod_{j=0}^{n}(|x-x_j|) \leq (n+1)!h^{n+1} \quad \text{for} \quad x \in [a,b]\nonumber
% \end{equation}
% With Stirling's approximation for $n!$
% \begin{equation}\nonumber
%     n! \sim e^{-n}n^n\sqrt{2\pi n } \tx{as} n \to +\infty \nonumber
% \end{equation}h
%for continue: https://services.math.duke.edu/~jtwong/math563-2020/lectures/Lec1-polyinterp.pdf  pp:11